{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Version of Fuzzy Account Matcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses mock data and replicates the logic used in a real-world professional tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprietary data has been removed to protect client privacy. \n",
    "No real data is included, the structure and logic are demonstrated using placeholder file paths and mock setup to protect client confidentiality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import multiprocessing\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from joblib import Parallel, delayed\n",
    "import win32com.client as win32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CRM data. This would normally be read from Excel and contains addresses, account names, and ZIP codes.\n",
    "accounts_df = pd.read_excel(accounts_df = pd.read_excel(\"data/sample_clients.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and formatting the CRM dataset—combining street lines, formatting ZIP codes to 5 digits, and trimming whitespace from state names.\n",
    "accounts_df['Address'] = accounts_df['Address 1: Street 1'].astype(str) + \" \" + accounts_df['Address 1: Street 2'].fillna(\"\")\n",
    "accounts_df['Name'] = accounts_df['Account Name'].copy()\n",
    "accounts_df['ZIP'] = accounts_df['Address 1: ZIP/Postal Code'].copy()\n",
    "accounts_df['State'] = accounts_df['Address 1: State/Province'].copy()\n",
    "accounts_df['State'] = accounts_df['State'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring all ZIP codes in the CRM file are 5 digits.\n",
    "accounts_df['ZIP'] = accounts_df['ZIP'].str[:5].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing spaces from account names to prepare for string-based fuzzy matching.\n",
    "accounts_df['Name'] = accounts_df['Name'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the retail client data from Excel. These are the records we’ll try to match to CRM accounts.\n",
    "retail_df = pd.read_excel(retail_df = pd.read_excel(\"data/unmapped_clients_sample.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and standardizing the retail dataset—ZIP codes are padded to 5 digits, and address columns are renamed to match the CRM format.\n",
    "retail_df['Zip'] = retail_df['Zip'].astype(str)\n",
    "retail_df['Zip'] = retail_df['Zip'].str[:5].str.zfill(5)\n",
    "retail_df.rename(columns={'Zip': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the cleaned retail dataset before matching.\n",
    "retail_df = retail_df.rename(columns={'Standard_Address': 'Address'})\n",
    "retail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs fuzzy string matching between a retail address and all CRM addresses within the same ZIP or State. It returns the top few closest matches with their scores.\n",
    "def find_best_match(row, restriction_column, match_column, choices_df, limit=5):\n",
    "    value = row[restriction_column]\n",
    "    choices_same_value = choices_df[choices_df[restriction_column] == value][match_column]\n",
    "    if choices_same_value.empty:\n",
    "        # Return a default value or handle it accordingly\n",
    "        return pd.Series([row[match_column], value, None, None], index=[f'Merge {match_column}', restriction_column, 'Best Match', 'Score'])\n",
    "    else:\n",
    "        matches = process.extract(row[match_column], choices_same_value, limit=limit)\n",
    "        return pd.Series([row[match_column], value, matches], index=[f'Merge {match_column}', restriction_column, 'Best Matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function applies fuzzy matching to a chunk of the dataset. We'll use this later when splitting the work across CPU cores.\n",
    "# Define a function to be applied in parallel\n",
    "def parallel_find_best_match(chunk, restriction_column, match_column, choices_df, limit):\n",
    "    return chunk.apply(find_best_match, restriction_column=restriction_column, match_column=match_column, choices_df=choices_df, limit=limit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here’s the full function that runs fuzzy matching in parallel across all rows. It handles chunking, matching, and formatting the results into clean columns.\n",
    "def run_parallel_find_best_match(retail_df, restriction_column='State', match_column='Address', choices_df=accounts_df, limit=2):                               \n",
    "    # Define the number of CPU cores to use\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    \n",
    "    # Split the exercise DataFrame into chunks for parallel processing\n",
    "    \n",
    "    # If there aren't many observations, you only need one chunk (will break if more than cores)\n",
    "    if len(retail_df) < num_cores:\n",
    "        chunk_size = 1\n",
    "    else:\n",
    "        chunk_size = len(retail_df) // num_cores\n",
    "    chunks = [retail_df.iloc[i:i+chunk_size] for i in range(0, len(retail_df), chunk_size)]\n",
    "    \n",
    "    # Run the parallel processing using joblib\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(parallel_find_best_match)(chunk, restriction_column, match_column, choices_df, limit) for chunk in chunks)\n",
    "    \n",
    "    # Concatenate the results from all processes\n",
    "    best_matches_df = pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    # Reset the index of the DataFrame\n",
    "    best_matches_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # Function to split tuples into separate columns\n",
    "    def split_tuples_to_columns(row):\n",
    "        tuples = row['Best Matches']\n",
    "        num_tuples = limit\n",
    "        for i, t in enumerate(tuples):\n",
    "            row[f'Match {i+1}'] = t[0]\n",
    "            row[f'Score {i+1}'] = t[1]\n",
    "            row[f'Drop {i+1}'] = t[2]\n",
    "            \n",
    "        return row\n",
    "\n",
    "    # Allow for errors (this is likely because the restriction column categories don't match the CRM, like the retail file may have full state vs the CRM's abbreviation)\n",
    "    def split_tuples_to_columns2(row):\n",
    "        try:\n",
    "            row = split_tuples_to_columns(row)\n",
    "            return row\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    # Apply the function to split tuples into separate columns\n",
    "    best_matches_df = best_matches_df.apply(split_tuples_to_columns2, axis=1)\n",
    "\n",
    "    # Drop the original 'Best Matches' column\n",
    "    best_matches_df.drop(columns=['Best Matches'], inplace=True)\n",
    "\n",
    "    # Filter out columns containing \"Drop\" in their name and drop them\n",
    "    best_matches_df = best_matches_df.filter(regex='^(?!.*Drop).*')\n",
    "\n",
    "    \n",
    "    return best_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the fuzzy matcher on the retail dataset. This will return the top 2 closest CRM matches for each retail address, limited by ZIP code.\n",
    "%%time\n",
    "# Find best matches\n",
    "retail_matches_df = run_parallel_find_best_match(retail_df, restriction_column='ZIP', match_column='Address', choices_df=accounts_df, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we’ve found the best matches, we merge them back with CRM data to pull in account names and numbers for each matched address.\n",
    "# Merge on account info from CRM\n",
    "accounts_df2 = accounts_df.drop_duplicates(['Address'], keep='first')\n",
    "retail_matches_df_with_accounts = retail_matches_df.merge(accounts_df2[['Address', 'Account Number', 'Account Name']], left_on=['Match 1'], right_on=['Address'], how='left')\n",
    "retail_matches_df_with_accounts = retail_matches_df_with_accounts.merge(accounts_df2[['Address', 'Account Number', 'Account Name']], left_on=['Match 2'], right_on=['Address'], how='left', suffixes=(\" 1\", \" 2\"))\n",
    "retail_matches_df_with_accounts = retail_matches_df_with_accounts[['Merge Address', 'Match 1', 'Score 1', 'Account Number 1','Account Name 1', 'Match 2', 'Score 2', 'Account Number 2', 'Account Name 2']]\n",
    "\n",
    "retail_matches_df_with_accounts['Practice Name'] = retail_df['Practice Name']\n",
    "\n",
    "retail_matches_df_with_accounts = retail_matches_df_with_accounts[['Practice Name', 'Merge Address', 'Match 1', 'Score 1', 'Account Number 1',\n",
    "       'Account Name 1', 'Match 2', 'Score 2', 'Account Number 2',\n",
    "       'Account Name 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final matched results to an Excel file. This file can be used for reporting or CRM updates.\n",
    "file_path = \"data/client_report_by_zip.xlsx\"\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "retail_matches_df_with_accounts.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
